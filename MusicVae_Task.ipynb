{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 설치 파일"
      ],
      "metadata": {
        "id": "O_A_p92gYYs7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 다운로드"
      ],
      "metadata": {
        "id": "qmKzy2t_YfqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "groove zip파일 gdown으로 다운로드"
      ],
      "metadata": {
        "id": "o89ufworYllM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pdtrzPuYQZu",
        "outputId": "b80723b1-f40e-4389-b544-5e956e94702e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xyP9fEB6hgzah6D8c3xjXu7mpzhqssOE\n",
            "To: /content/groove-v1.0.0-midionly.zip\n",
            "\r  0% 0.00/3.26M [00:00<?, ?B/s]\r100% 3.26M/3.26M [00:00<00:00, 252MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1xyP9fEB6hgzah6D8c3xjXu7mpzhqssOE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## magenta 패키지 설치"
      ],
      "metadata": {
        "id": "MqGb-wUfYuGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|erorr note| dependency 이슈: magenta 2.1.0 버전 설치"
      ],
      "metadata": {
        "id": "xzDIkGMHY38h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install magenta==2.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_HxCsKKTY3Z4",
        "outputId": "bb7622b7-a39b-43c0-bd6d-2c464bacf2a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting magenta==2.1.0\n",
            "  Downloading magenta-2.1.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 15.7 MB/s \n",
            "\u001b[?25hCollecting mido==1.2.6\n",
            "  Downloading mido-1.2.6-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (1.7.3)\n",
            "Collecting mir-eval>=0.4\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 12.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=1.5.3 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (3.2.2)\n",
            "Collecting pretty-midi>=0.2.6\n",
            "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 58.3 MB/s \n",
            "\u001b[?25hCollecting note-seq\n",
            "  Downloading note_seq-0.0.5-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 62.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: librosa>=0.6.2 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (0.8.1)\n",
            "Collecting pygtrie>=2.3\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (0.17.0)\n",
            "Collecting sox>=1.3.7\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (2.9.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: Pillow>=3.4.2 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (7.1.2)\n",
            "Collecting dm-sonnet\n",
            "  Downloading dm_sonnet-2.0.1-py3-none-any.whl (268 kB)\n",
            "\u001b[K     |████████████████████████████████| 268 kB 73.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (1.21.6)\n",
            "Collecting sk-video\n",
            "  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 73.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (4.6.0)\n",
            "Collecting numba<0.50\n",
            "  Downloading numba-0.49.1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 72.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (2.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from magenta==2.1.0) (0.38.4)\n",
            "Collecting apache-beam[gcp]>=2.14.0\n",
            "  Downloading apache_beam-2.43.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 69.9 MB/s \n",
            "\u001b[?25hCollecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 80.5 MB/s \n",
            "\u001b[?25hCollecting tensor2tensor\n",
            "  Downloading tensor2tensor-1.15.7-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 69.5 MB/s \n",
            "\u001b[?25hCollecting python-rtmidi<1.2,>=1.1\n",
            "  Downloading python-rtmidi-1.1.2.tar.gz (204 kB)\n",
            "\u001b[K     |████████████████████████████████| 204 kB 10.2 MB/s \n",
            "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
            "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
            "Collecting pymongo<4.0.0,>=3.8.0\n",
            "  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n",
            "\u001b[K     |████████████████████████████████| 526 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting objsize<0.6.0,>=0.5.2\n",
            "  Downloading objsize-0.5.2-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.3.0)\n",
            "Collecting fasteners<1.0,>=0.3\n",
            "  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2022.6.2)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.7)\n",
            "Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (3.19.6)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.22.1)\n",
            "Collecting zstandard<1,>=0.18.0\n",
            "  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 65.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (0.17.4)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.51.1)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2022.6)\n",
            "Collecting orjson<4.0\n",
            "  Downloading orjson-3.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (278 kB)\n",
            "\u001b[K     |████████████████████████████████| 278 kB 76.0 MB/s \n",
            "\u001b[?25hCollecting cloudpickle~=2.2.0\n",
            "  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting dill<0.3.2,>=0.3.1.1\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 76.7 MB/s \n",
            "\u001b[?25hCollecting requests<3.0.0,>=2.24.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (9.0.0)\n",
            "Collecting fastavro<2,>=0.23.6\n",
            "  Downloading fastavro-1.7.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (4.4.0)\n",
            "Collecting google-cloud-spanner<4,>=3.0.0\n",
            "  Downloading google_cloud_spanner-3.26.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 71.0 MB/s \n",
            "\u001b[?25hCollecting google-cloud-dlp<4,>=3.0.0\n",
            "  Downloading google_cloud_dlp-3.10.0-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 80.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-core<3,>=0.28.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.3.2)\n",
            "Requirement already satisfied: google-cloud-bigquery<4,>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (3.3.6)\n",
            "Collecting google-apitools<0.5.32,>=0.5.31\n",
            "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
            "\u001b[K     |████████████████████████████████| 173 kB 78.4 MB/s \n",
            "\u001b[?25hCollecting google-cloud-bigquery-storage<2.14,>=2.6.3\n",
            "  Downloading google_cloud_bigquery_storage-2.13.2-py2.py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 73.2 MB/s \n",
            "\u001b[?25hCollecting google-cloud-language<2,>=1.3.0\n",
            "  Downloading google_cloud_language-1.3.2-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting google-cloud-vision<2,>=0.38.0\n",
            "  Downloading google_cloud_vision-1.0.2-py2.py3-none-any.whl (435 kB)\n",
            "\u001b[K     |████████████████████████████████| 435 kB 68.7 MB/s \n",
            "\u001b[?25hCollecting cachetools<5,>=3.1.0\n",
            "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting google-cloud-videointelligence<2,>=1.8.0\n",
            "  Downloading google_cloud_videointelligence-1.16.3-py2.py3-none-any.whl (183 kB)\n",
            "\u001b[K     |████████████████████████████████| 183 kB 80.2 MB/s \n",
            "\u001b[?25hCollecting google-cloud-pubsublite<2,>=1.2.0\n",
            "  Downloading google_cloud_pubsublite-1.6.0-py2.py3-none-any.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 74.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.15.0)\n",
            "Collecting google-cloud-bigtable<2,>=0.31.1\n",
            "  Downloading google_cloud_bigtable-1.7.3-py2.py3-none-any.whl (268 kB)\n",
            "\u001b[K     |████████████████████████████████| 268 kB 76.4 MB/s \n",
            "\u001b[?25hCollecting google-auth-httplib2<0.2.0,>=0.1.0\n",
            "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting google-cloud-recommendations-ai<0.8.0,>=0.1.0\n",
            "  Downloading google_cloud_recommendations_ai-0.7.1-py2.py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 80.5 MB/s \n",
            "\u001b[?25hCollecting google-cloud-pubsub<3,>=2.1.0\n",
            "  Downloading google_cloud_pubsub-2.13.11-py2.py3-none-any.whl (236 kB)\n",
            "\u001b[K     |████████████████████████████████| 236 kB 78.7 MB/s \n",
            "\u001b[?25hCollecting google-cloud-datastore<2,>=1.8.0\n",
            "  Downloading google_cloud_datastore-1.15.5-py2.py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 80.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client>=1.4.12 in /usr/local/lib/python3.8/dist-packages (from google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (4.1.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<4,>=1.6.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<4,>=1.6.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.4.0)\n",
            "Requirement already satisfied: packaging<22.0.0dev,>=14.3 in /usr/local/lib/python3.8/dist-packages (from google-cloud-bigquery<4,>=1.6.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery<4,>=1.6.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.57.0)\n",
            "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery<4,>=1.6.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.48.2)\n",
            "Collecting grpc-google-iam-v1<0.13dev,>=0.12.3\n",
            "  Downloading grpc_google_iam_v1-0.12.4-py2.py3-none-any.whl (26 kB)\n",
            "Collecting google-cloud-dlp<4,>=3.0.0\n",
            "  Downloading google_cloud_dlp-3.9.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 84.7 MB/s \n",
            "\u001b[?25hCollecting overrides<7.0.0,>=6.0.1\n",
            "  Downloading overrides-6.5.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: sqlparse>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (0.4.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.8/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4,>=1.6.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.5.0)\n",
            "Collecting docopt\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (1.0.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (1.2.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (0.4.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (1.6.0)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa>=0.6.2->magenta==2.1.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.3->magenta==2.1.0) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.3->magenta==2.1.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.3->magenta==2.1.0) (1.4.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from mir-eval>=0.4->magenta==2.1.0) (0.16.0)\n",
            "Collecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0\n",
            "  Downloading llvmlite-0.32.1-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba<0.50->magenta==2.1.0) (57.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client>=1.4.12->google-apitools<0.5.32,>=0.5.31->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa>=0.6.2->magenta==2.1.0) (1.4.4)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam[gcp]>=2.14.0->magenta==2.1.0) (2022.12.7)\n",
            "Collecting resampy>=0.2.2\n",
            "  Downloading resampy-0.4.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 59.9 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 73.1 MB/s \n",
            "\u001b[?25h  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 68.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.6.2->magenta==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa>=0.6.2->magenta==2.1.0) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.6.2->magenta==2.1.0) (2.21)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from dm-sonnet->magenta==2.1.0) (1.14.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from dm-sonnet->magenta==2.1.0) (0.1.7)\n",
            "Requirement already satisfied: tabulate>=0.7.5 in /usr/local/lib/python3.8/dist-packages (from dm-sonnet->magenta==2.1.0) (0.8.10)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.8/dist-packages (from note-seq->magenta==2.1.0) (22.1.0)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from note-seq->magenta==2.1.0) (7.9.0)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from note-seq->magenta==2.1.0) (1.3.5)\n",
            "Requirement already satisfied: bokeh>=0.12.0 in /usr/local/lib/python3.8/dist-packages (from note-seq->magenta==2.1.0) (2.3.3)\n",
            "Collecting note-seq\n",
            "  Downloading note_seq-0.0.4-py3-none-any.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 75.4 MB/s \n",
            "\u001b[?25h  Downloading note_seq-0.0.3-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: intervaltree>=2.1.0 in /usr/local/lib/python3.8/dist-packages (from note-seq->magenta==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.8/dist-packages (from bokeh>=0.12.0->note-seq->magenta==2.1.0) (6.0.4)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from bokeh>=0.12.0->note-seq->magenta==2.1.0) (2.11.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.8/dist-packages (from bokeh>=0.12.0->note-seq->magenta==2.1.0) (6.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.8/dist-packages (from intervaltree>=2.1.0->note-seq->magenta==2.1.0) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.9->bokeh>=0.12.0->note-seq->magenta==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq->magenta==2.1.0) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq->magenta==2.1.0) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 66.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq->magenta==2.1.0) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq->magenta==2.1.0) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq->magenta==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->note-seq->magenta==2.1.0) (5.7.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->note-seq->magenta==2.1.0) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->note-seq->magenta==2.1.0) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->note-seq->magenta==2.1.0) (0.7.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (from tensor2tensor->magenta==2.1.0) (1.1.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.8/dist-packages (from tensor2tensor->magenta==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from tensor2tensor->magenta==2.1.0) (1.7.1)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tensor2tensor->magenta==2.1.0) (0.5.0)\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 62.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensor2tensor->magenta==2.1.0) (4.64.1)\n",
            "Collecting kfac\n",
            "  Downloading kfac-0.2.4-py2.py3-none-any.whl (193 kB)\n",
            "\u001b[K     |████████████████████████████████| 193 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (from tensor2tensor->magenta==2.1.0) (0.25.2)\n",
            "Collecting bz2file\n",
            "  Downloading bz2file-0.98.tar.gz (11 kB)\n",
            "Collecting tensorflow-gan\n",
            "  Downloading tensorflow_gan-2.1.0-py2.py3-none-any.whl (367 kB)\n",
            "\u001b[K     |████████████████████████████████| 367 kB 66.6 MB/s \n",
            "\u001b[?25hCollecting pypng\n",
            "  Downloading pypng-0.20220715.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.8/dist-packages (from tensor2tensor->magenta==2.1.0) (1.12.11)\n",
            "Collecting gevent\n",
            "  Downloading gevent-22.10.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 70.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (from tensor2tensor->magenta==2.1.0) (4.6.0.66)\n",
            "Collecting tensorflow-probability\n",
            "  Downloading tensorflow_probability-0.7.0-py2.py3-none-any.whl (981 kB)\n",
            "\u001b[K     |████████████████████████████████| 981 kB 65.0 MB/s \n",
            "\u001b[?25hCollecting mesh-tensorflow\n",
            "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
            "\u001b[K     |████████████████████████████████| 385 kB 68.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dopamine-rl in /usr/local/lib/python3.8/dist-packages (from tensor2tensor->magenta==2.1.0) (1.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym->tensor2tensor->magenta==2.1.0) (5.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym->tensor2tensor->magenta==2.1.0) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym->tensor2tensor->magenta==2.1.0) (3.11.0)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from flask->tensor2tensor->magenta==2.1.0) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from flask->tensor2tensor->magenta==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from flask->tensor2tensor->magenta==2.1.0) (1.0.1)\n",
            "Collecting zope.interface\n",
            "  Downloading zope.interface-5.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (261 kB)\n",
            "\u001b[K     |████████████████████████████████| 261 kB 71.7 MB/s \n",
            "\u001b[?25hCollecting zope.event\n",
            "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: greenlet>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from gevent->tensor2tensor->magenta==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client->tensor2tensor->magenta==2.1.0) (3.0.1)\n",
            "Collecting kfac\n",
            "  Downloading kfac-0.2.3-py2.py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 76.3 MB/s \n",
            "\u001b[?25h  Downloading kfac-0.2.2-py2.py3-none-any.whl (191 kB)\n",
            "\u001b[K     |████████████████████████████████| 191 kB 78.3 MB/s \n",
            "\u001b[?25h  Downloading kfac-0.2.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[K     |████████████████████████████████| 178 kB 77.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->tensor2tensor->magenta==2.1.0) (1.2.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (0.28.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (14.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (2.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (1.6.3)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (1.12)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow->magenta==2.1.0) (2.9.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (1.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->magenta==2.1.0) (3.2.2)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tensor2tensor->magenta==2.1.0) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->magenta==2.1.0) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->magenta==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->magenta==2.1.0) (5.10.1)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->magenta==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->magenta==2.1.0) (0.10.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-gan->tensor2tensor->magenta==2.1.0) (0.12.0)\n",
            "Building wheels for collected packages: dill, google-apitools, mir-eval, pretty-midi, python-rtmidi, docopt, bz2file\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=9fb1090da00f68f68a3af19de99e84c02a7c2f61f937148dba0e892f7620c1bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131041 sha256=5e307e75060907b0cbf07d55bf50f30ea724762cc74bd66efcc9a031b2301012\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/54/79/85de1824f2f4175fb4960c72afb10045d86700c3941dc73685\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.7-py3-none-any.whl size=100720 sha256=35a86f5d7f1cd70cbba433c73813983508a1536e9ea5ba7667b239d011a331d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/53/83/1d50d15a666140d53eda589db005f7cb53b739c7e54711f51f\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591954 sha256=5820c37b4ec446892eb7fdaa85c7f23477f03279ce37a9eb507f311bd20585f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/5a/e3/30eeb9a99350f3f7e21258fcb132743eef1a4f49b3505e76b6\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-rtmidi: filename=python_rtmidi-1.1.2-cp38-cp38-linux_x86_64.whl size=417624 sha256=594f3136dc4cee9401f954f846f89bbf65252b9ed3000df5c56e51188b199e9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/93/e9/7d805b982c4cb5c6cec3e77e1fc6e7417a193beca2230cea52\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=48b13dc9cef869c94ec110d566d2a6c1833cad1964013b104d5e0374d0ba5db1\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "  Building wheel for bz2file (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bz2file: filename=bz2file-0.98-py3-none-any.whl size=6882 sha256=fd1b29d408e81ed910afed930c4b21b0cb55e842477e0757eea961eac822270b\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/88/ce/c9430af242507ffff602cf86c5ff6a1ae5205cba5aaf21f6cc\n",
            "Successfully built dill google-apitools mir-eval pretty-midi python-rtmidi docopt bz2file\n",
            "Installing collected packages: cachetools, requests, llvmlite, numba, grpc-google-iam-v1, docopt, cloudpickle, zstandard, zope.interface, zope.event, tensorflow-probability, resampy, pymongo, overrides, orjson, objsize, mido, jedi, hdfs, google-cloud-pubsub, google-cloud-bigquery-storage, google-auth-httplib2, fasteners, fastavro, dill, tf-slim, tensorflow-gan, tensorflow-addons, pypng, pydub, pretty-midi, mesh-tensorflow, kfac, gunicorn, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsublite, google-cloud-language, google-cloud-dlp, google-cloud-datastore, google-cloud-bigtable, google-apitools, gevent, bz2file, apache-beam, tensor2tensor, sox, sk-video, python-rtmidi, pygtrie, note-seq, mir-eval, dm-sonnet, magenta\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.2.0\n",
            "    Uninstalling cachetools-5.2.0:\n",
            "      Successfully uninstalled cachetools-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.5.0\n",
            "    Uninstalling cloudpickle-1.5.0:\n",
            "      Successfully uninstalled cloudpickle-1.5.0\n",
            "  Attempting uninstall: tensorflow-probability\n",
            "    Found existing installation: tensorflow-probability 0.17.0\n",
            "    Uninstalling tensorflow-probability-0.17.0:\n",
            "      Successfully uninstalled tensorflow-probability-0.17.0\n",
            "  Attempting uninstall: resampy\n",
            "    Found existing installation: resampy 0.4.2\n",
            "    Uninstalling resampy-0.4.2:\n",
            "      Successfully uninstalled resampy-0.4.2\n",
            "  Attempting uninstall: pymongo\n",
            "    Found existing installation: pymongo 4.3.3\n",
            "    Uninstalling pymongo-4.3.3:\n",
            "      Successfully uninstalled pymongo-4.3.3\n",
            "  Attempting uninstall: google-cloud-bigquery-storage\n",
            "    Found existing installation: google-cloud-bigquery-storage 2.16.2\n",
            "    Uninstalling google-cloud-bigquery-storage-2.16.2:\n",
            "      Successfully uninstalled google-cloud-bigquery-storage-2.16.2\n",
            "  Attempting uninstall: google-auth-httplib2\n",
            "    Found existing installation: google-auth-httplib2 0.0.4\n",
            "    Uninstalling google-auth-httplib2-0.0.4:\n",
            "      Successfully uninstalled google-auth-httplib2-0.0.4\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.6\n",
            "    Uninstalling dill-0.3.6:\n",
            "      Successfully uninstalled dill-0.3.6\n",
            "  Attempting uninstall: google-cloud-language\n",
            "    Found existing installation: google-cloud-language 2.6.1\n",
            "    Uninstalling google-cloud-language-2.6.1:\n",
            "      Successfully uninstalled google-cloud-language-2.6.1\n",
            "  Attempting uninstall: google-cloud-datastore\n",
            "    Found existing installation: google-cloud-datastore 2.9.0\n",
            "    Uninstalling google-cloud-datastore-2.9.0:\n",
            "      Successfully uninstalled google-cloud-datastore-2.9.0\n",
            "Successfully installed apache-beam-2.43.0 bz2file-0.98 cachetools-4.2.4 cloudpickle-2.2.0 dill-0.3.1.1 dm-sonnet-2.0.1 docopt-0.6.2 fastavro-1.7.0 fasteners-0.18 gevent-22.10.2 google-apitools-0.5.31 google-auth-httplib2-0.1.0 google-cloud-bigquery-storage-2.13.2 google-cloud-bigtable-1.7.3 google-cloud-datastore-1.15.5 google-cloud-dlp-3.9.2 google-cloud-language-1.3.2 google-cloud-pubsub-2.13.11 google-cloud-pubsublite-1.6.0 google-cloud-recommendations-ai-0.7.1 google-cloud-spanner-3.26.0 google-cloud-videointelligence-1.16.3 google-cloud-vision-1.0.2 grpc-google-iam-v1-0.12.4 gunicorn-20.1.0 hdfs-2.7.0 jedi-0.18.2 kfac-0.2.0 llvmlite-0.32.1 magenta-2.1.0 mesh-tensorflow-0.1.21 mido-1.2.6 mir-eval-0.7 note-seq-0.0.3 numba-0.49.1 objsize-0.5.2 orjson-3.8.3 overrides-6.5.0 pretty-midi-0.2.9 pydub-0.25.1 pygtrie-2.5.0 pymongo-3.13.0 pypng-0.20220715.0 python-rtmidi-1.1.2 requests-2.28.1 resampy-0.3.1 sk-video-1.1.10 sox-1.4.1 tensor2tensor-1.15.7 tensorflow-addons-0.19.0 tensorflow-gan-2.1.0 tensorflow-probability-0.7.0 tf-slim-1.1.0 zope.event-4.6 zope.interface-5.5.2 zstandard-0.19.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리"
      ],
      "metadata": {
        "id": "uGtrJO1TZB40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전처리 이유\n",
        "- midi데이터를 학습하기위해, 백터화 작업 필요요.\n",
        "- Magenta의 convert_directory 이용해 전처리\n",
        "- zip파일로 다운받고 zipfile 라이브러리로 압축 해제 후, 백터화\n",
        "- 백터화하여 TFrecord로 저장"
      ],
      "metadata": {
        "id": "xc4ieVLyZGPo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TFRecord 파일은 tensorflow의 학습 데이터등을 저장하기 위한 이진 데이터 포맷으로, 구글의 Protocol Buffer 포맷으로 데이터를 파일에 직렬화하여 저장\n",
        "\n",
        "필요성\n",
        "- 이미지 데이터와 같은 데이터는 메타데이터와 레이블이 별도의 파일로 저장되어 있기 때문에, 각각 읽어들여야해서 코드가 복잡해짐.TFrecord 파일을 이용하면 훨씬 간단하게 해결 가능.\n",
        "- midi 포맷맷으로 읽어서 매번 디코딩을 진행하면 학습단계에서 데이터를 읽을때 성능저하가 발생. 이를 해결하기 위해 TFrecord 파일을 사용 가능."
      ],
      "metadata": {
        "id": "i1qEFv5lZhtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요 module\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pathlib # 경로를 객체로 처리하기위해\n",
        "import zipfile # zip파일 압축 해제를 위해\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import pandas as pd\n",
        "import IPython\n",
        "import collections\n",
        "import note_seq # 시퀀스 midi화\n",
        "\n",
        "import magenta.music as mm\n",
        "from magenta.common import merge_hparams\n",
        "from magenta.contrib import training as contrib_training\n",
        "from magenta.models.music_vae import MusicVAE\n",
        "from magenta.models.music_vae import lstm_models\n",
        "from magenta.models.music_vae import data\n",
        "from magenta.scripts.convert_dir_to_note_sequences import convert_directory # 전처리\n",
        "from magenta.models.music_vae import configs\n",
        "from magenta.models.music_vae.trained_model import TrainedModel # 훈련 모델\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tf_slim # TF-Slim은 저수준의 텐서플로우 API를 간편하게 사용할 수 있는 고수준 경량 API"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRXrAXfBZFCF",
        "outputId": "75354f7d-1584-45a0-8545-993f3be8bac2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# zip파일 압축해제\n",
        "zipfile.ZipFile('./groove-v1.0.0-midionly.zip').extractall()"
      ],
      "metadata": {
        "id": "_o4pvVLHaRmD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TFRecord 저장할 디렉토리 생성성\n",
        "os.mkdir(\"data_TFRecord\")"
      ],
      "metadata": {
        "id": "eCT1PZ_baVCv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로지정\n",
        "data_root= './groove' # 데이터 경로\n",
        "csv_file = './groove/info.csv' # midi 파일의 session, id, bpm 정보를 담고있음.\n",
        "tfrec_root = './data_TFRecord/music.tfrecord'# TFRecord 파일 경로를 지정"
      ],
      "metadata": {
        "id": "LH8bHNwlajv1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 확인인\n",
        "df = pd.read_csv('./groove/info.csv')\n",
        "df = pd.DataFrame(df)\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "BIABfUm8aq5p",
        "outputId": "1a331c40-94b7-4515-9efa-063016b37b49"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    drummer                session                        id          style  \\\n",
              "0  drummer1  drummer1/eval_session   drummer1/eval_session/1   funk/groove1   \n",
              "1  drummer1  drummer1/eval_session  drummer1/eval_session/10  soul/groove10   \n",
              "2  drummer1  drummer1/eval_session   drummer1/eval_session/2   funk/groove2   \n",
              "\n",
              "   bpm beat_type time_signature  \\\n",
              "0  138      beat            4-4   \n",
              "1  102      beat            4-4   \n",
              "2  105      beat            4-4   \n",
              "\n",
              "                                       midi_filename  \\\n",
              "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
              "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
              "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
              "\n",
              "                                      audio_filename   duration split  \n",
              "0  drummer1/eval_session/1_funk-groove1_138_beat_...  27.872308  test  \n",
              "1  drummer1/eval_session/10_soul-groove10_102_bea...  37.691158  test  \n",
              "2  drummer1/eval_session/2_funk-groove2_105_beat_...  36.351218  test  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac1f36bd-329d-424b-ae2f-91e1eafadbe8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drummer</th>\n",
              "      <th>session</th>\n",
              "      <th>id</th>\n",
              "      <th>style</th>\n",
              "      <th>bpm</th>\n",
              "      <th>beat_type</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>midi_filename</th>\n",
              "      <th>audio_filename</th>\n",
              "      <th>duration</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/1</td>\n",
              "      <td>funk/groove1</td>\n",
              "      <td>138</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>27.872308</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/10</td>\n",
              "      <td>soul/groove10</td>\n",
              "      <td>102</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>37.691158</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/2</td>\n",
              "      <td>funk/groove2</td>\n",
              "      <td>105</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>36.351218</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac1f36bd-329d-424b-ae2f-91e1eafadbe8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac1f36bd-329d-424b-ae2f-91e1eafadbe8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac1f36bd-329d-424b-ae2f-91e1eafadbe8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 전처리 진행(TFRecord화)"
      ],
      "metadata": {
        "id": "v8_CQY11a3tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convert_directory(data_root,tfrec_root,recursive=True) # 전처리 함수함수"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdJCZBMFa9ul",
        "outputId": "a18ee86f-86e2-47e6-b64b-556dc1efe9c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unable to find a converter for file ./groove/README\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/info.csv\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/LICENSE\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer1/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer1/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer1/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer1/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer9/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer9/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer10/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer10/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer6/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer6/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer6/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer6/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer7/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer7/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer7/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer7/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer7/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer3/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer3/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer2/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer2/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer2/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer8/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer8/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer8/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer8/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer5/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer5/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer5/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer5/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer4/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file ./groove/drummer4/session1/Icon\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "R2VH5g0gbMr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Config 정의"
      ],
      "metadata": {
        "id": "O6m1RAmqbTPB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- magenta/blob/main/magenta/models/music_vae/configs.py 수정\n",
        "- 모델과 함께 전체 config를 수정\n",
        "- TFRecord 경로지정"
      ],
      "metadata": {
        "id": "XFb7GEB5bYRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 구조"
      ],
      "metadata": {
        "id": "a1GwTntb3sTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder** : BidirectionalLSTM(양방향 LSTM)\n",
        "- 2계층 양방향 LSTM\n",
        " - 역방향(미래에서 과거) 또는 정방향(과거에서 미래) 두 양방향으로 시퀀스 정보를 갖도록 만듬.  \n",
        " - BidirectionalLSTM 을 사용하면 미래와 과거의 정보를 보전하기위해 양방향으로 입력흐름을 만들수 있음.\n",
        "- NLP모델인 BERT에서도 사용  \n",
        "\n",
        "**Decoder** : Hierarchical Decoder(CategoricalLstm)  \n",
        "- Simple RNN 사용 하면 기울기소실로 성능저하\n",
        " - 하위 시퀀스 간의 복잡한 종속성을 갖는 계층구조 생성 프로세스를 모델링 하기위해 다양한 시간단계에 걸쳐, 잠재 확률 변수를 사용한 신경망 기반 생성 아키텍처\n",
        "- NLP모델에서 많이사용"
      ],
      "metadata": {
        "id": "ni2yj7BP3u8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# configs.py 일부 발췌\n",
        "\n",
        "class Config(collections.namedtuple(\n",
        "    'Config',\n",
        "    ['model', 'hparams', 'note_sequence_augmenter', 'data_converter',\n",
        "     'train_examples_path', 'eval_examples_path', 'tfds_name'])):\n",
        "\n",
        "    def values(self):\n",
        "        return self._asdict()\n",
        "\n",
        "Config.__new__.__defaults__ = (None,) * len(Config._fields)\n",
        "\n",
        "\n",
        "def update_config(config, update_dict):\n",
        "    config_dict = config.values()\n",
        "    config_dict.update(update_dict)\n",
        "    return Config(**config_dict)\n",
        "\n",
        "\n",
        "CONFIG_MAP = {}\n",
        "\n",
        "\n",
        "HParams = contrib_training.HParams\n",
        "\n",
        "# 모델 config configs.py에서 4마디 드럼 파일을 선택 위해 'cat-drums_2bar_small'내용을 인용\n",
        "\n",
        "# 모델구조\n",
        "CONFIG_MAP['cat-drums_4bar_small'] = Config(\n",
        "    model=MusicVAE(lstm_models.BidirectionalLstmEncoder(),  # BidirectionalLstm Encoder 사용\n",
        "                   lstm_models.CategoricalLstmDecoder()),  # Hierarchical Decoder 사용\n",
        "    hparams=merge_hparams(\n",
        "        lstm_models.get_default_hparams(),\n",
        "        HParams(\n",
        "            batch_size=512,  # 데이터 배치사이즈\n",
        "            max_seq_len=16 * 4,  # 4마디 길이지정\n",
        "            z_size=256, # 잠재백터 사이즈, 잠재 공간(latent space) 설정정\n",
        "            enc_rnn_size=[512], # 인코더 순환 사이즈지정\n",
        "            dec_rnn_size=[256, 256], # 디코더 순환사이즈 지정\n",
        "            free_bits=48,\n",
        "            max_beta=0.2,\n",
        "            sampling_schedule='inverse_sigmoid',\n",
        "            sampling_rate=1000,\n",
        "        )),\n",
        "    note_sequence_augmenter=None,\n",
        "    data_converter=data.DrumsConverter( # 드럼 파일만 선택\n",
        "        max_bars=100,\n",
        "        slice_bars=4, # 4 마디 단위로 시퀀스 나눔\n",
        "        steps_per_quarter=4,\n",
        "        roll_input=True,),\n",
        "    train_examples_path='./data_TFRecord/music.tfrecord', # 데이터 경로 설정\n",
        ")"
      ],
      "metadata": {
        "id": "DyUuvU6HbWo7"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 코드들 통해 전처리 해야하지만 구현 실패(생략하고 진행)"
      ],
      "metadata": {
        "id": "C_nhT7N4BHby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd ./magenta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzmoV9cC_iSh",
        "outputId": "347d2687-206e-46ae-802d-eb762deb64b0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/magenta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = 'cat-drums_4bar_small'\n",
        "\n",
        "!python -m magenta.models.music_vae.preprocess_tfrecord \\\n",
        "--input_tfrecord=/content/data_TFRecord/music.tfrecord \\\n",
        "--output_tfrecord=/content/data_TFRecord/train-$CONFIG.tfrecord \\\n",
        "--output_shards=10 \\\n",
        "--config=$CONFIG \\\n",
        "--is_drum=True \\\n",
        "--drums_only=True \\\n",
        "--alsologtostderr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI1ti2ym-Djt",
        "outputId": "be966952-02d3-4dec-8899-1748c14cea00"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/resampy/interpn.py:114: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  _resample_loop_p(x, t_out, interp_win, interp_delta, num_table, scale, y)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.8/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/magenta/magenta/models/music_vae/preprocess_tfrecord.py\", line 262, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/magenta/magenta/models/music_vae/preprocess_tfrecord.py\", line 257, in main\n",
            "    run_pipeline(FLAGS.input_tfrecord, FLAGS.output_tfrecord, FLAGS.output_shards,\n",
            "  File \"/content/magenta/magenta/models/music_vae/preprocess_tfrecord.py\", line 234, in run_pipeline\n",
            "    ExtractExamplesDoFn(config, filters))\n",
            "  File \"/content/magenta/magenta/models/music_vae/preprocess_tfrecord.py\", line 110, in __init__\n",
            "    self._config = configs.CONFIG_MAP[config_name]\n",
            "KeyError: ''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyJpNCbRBRCz",
        "outputId": "f6a2fd08-750e-47f6-f491-57b4c458bf16"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Model 정의"
      ],
      "metadata": {
        "id": "scfRmfJjc8JW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#============ License=====================================================\n",
        "# Copyright 2022 The Magenta Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "#=======================================================================\n",
        "\n",
        "#=== MusicVAE train script===\n",
        "#=== magenta/models/music_vae/music_vae_train.py ===\n",
        "\n",
        "def _trial_summary(hparams, examples_path, output_dir):\n",
        "     # 텐서보드 summary 텍스트\n",
        "\n",
        "    examples_path_summary = tf.summary.text(\n",
        "        'examples_path', tf.constant(examples_path, name='examples_path'),\n",
        "        collections=[])\n",
        "\n",
        "    hparams_dict = hparams.values()\n",
        "\n",
        "    # 하이퍼 파라미터\n",
        "    header = '| Key | Value |\\n| :--- | :--- |\\n'\n",
        "    keys = sorted(hparams_dict.keys())\n",
        "    lines = ['| %s | %s |' % (key, str(hparams_dict[key])) for key in keys]\n",
        "    hparams_table = header + '\\n'.join(lines) + '\\n'\n",
        "\n",
        "    hparam_summary = tf.summary.text(\n",
        "        'hparams', tf.constant(hparams_table, name='hparams'), collections=[])\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        writer = tf.summary.FileWriter(output_dir, graph=sess.graph)\n",
        "        writer.add_summary(examples_path_summary.eval())\n",
        "        writer.add_summary(hparam_summary.eval())\n",
        "        writer.close()\n",
        "\n",
        "\n",
        "def _get_input_tensors(dataset, config):\n",
        "    # 데이터로부터 텐서 입력\n",
        "    batch_size = config.hparams.batch_size\n",
        "    iterator = tf.data.make_one_shot_iterator(dataset)\n",
        "    (input_sequence, output_sequence, control_sequence,sequence_length) = iterator.get_next()\n",
        "    input_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.input_depth])\n",
        "    output_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.output_depth])\n",
        "    \n",
        "    if not config.data_converter.control_depth:\n",
        "        control_sequence = None\n",
        "    \n",
        "    else:\n",
        "        control_sequence.set_shape(\n",
        "            [batch_size, None, config.data_converter.control_depth])\n",
        "    sequence_length.set_shape([batch_size] + sequence_length.shape[1:].as_list())\n",
        "        \n",
        "    return {\n",
        "        'input_sequence': input_sequence,\n",
        "        'output_sequence': output_sequence,\n",
        "        'control_sequence': control_sequence,\n",
        "        'sequence_length': sequence_length\n",
        "    }\n",
        "\n",
        "# 훈련 체크포인트, 시간 설정\n",
        "def train(train_dir,\n",
        "          config,\n",
        "          dataset_fn,\n",
        "          checkpoints_to_keep=5,\n",
        "          keep_checkpoint_every_n_hours=1,\n",
        "          num_steps=None,\n",
        "          master='',\n",
        "          num_sync_workers=0,\n",
        "          num_ps_tasks=0,\n",
        "          task=0):\n",
        "\n",
        "    # train loop\n",
        "    tf.gfile.MakeDirs(train_dir)\n",
        "    is_chief = (task == 0)\n",
        "\n",
        "    with tf.Graph().as_default():\n",
        "        with tf.device(tf.train.replica_device_setter(\n",
        "                num_ps_tasks, merge_devices=True)):\n",
        "            \n",
        "            model = config.model\n",
        "            model.build(config.hparams,\n",
        "                        config.data_converter.output_depth,\n",
        "                        is_training=True)\n",
        "            # 옵티마이저\n",
        "            optimizer = model.train(**_get_input_tensors(dataset_fn(), config))\n",
        "\n",
        "            hooks = []\n",
        "            if num_sync_workers:\n",
        "                optimizer = tf.train.SyncReplicasOptimizer(\n",
        "                    optimizer,num_sync_workers)\n",
        "                hooks.append(optimizer.make_session_run_hook(is_chief))\n",
        "\n",
        "            grads, var_list = list(zip(*optimizer.compute_gradients(model.loss)))\n",
        "            global_norm = tf.global_norm(grads)\n",
        "            tf.summary.scalar('global_norm', global_norm)\n",
        "            \n",
        "            if config.hparams.clip_mode == 'value':\n",
        "                g = config.hparams.grad_clip\n",
        "                clipped_grads = [tf.clip_by_value(grad, -g, g) for grad in grads]\n",
        "            elif config.hparams.clip_mode == 'global_norm':\n",
        "                clipped_grads = tf.cond(\n",
        "                    global_norm < config.hparams.grad_norm_clip_to_zero,\n",
        "                    lambda: tf.clip_by_global_norm(  # pylint:disable=g-long-lambda\n",
        "                        grads, config.hparams.grad_clip, use_norm=global_norm)[0],\n",
        "                    lambda: [tf.zeros(tf.shape(g)) for g in grads])\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    'Unknown clip_mode: {}'.format(config.hparams.clip_mode))\n",
        "            train_op = optimizer.apply_gradients(\n",
        "                list(zip(clipped_grads, var_list)),\n",
        "                global_step=model.global_step,\n",
        "                name='train_step')\n",
        "\n",
        "            logging_dict = {'global_step': model.global_step,\n",
        "                            'loss': model.loss}\n",
        "            \n",
        "            hooks.append(tf.train.LoggingTensorHook(logging_dict, every_n_iter=100))\n",
        "            if num_steps:\n",
        "                hooks.append(tf.train.StopAtStepHook(last_step=num_steps))\n",
        "                \n",
        "            scaffold = tf.train.Scaffold(\n",
        "                saver=tf.train.Saver(\n",
        "                    max_to_keep=checkpoints_to_keep,\n",
        "                    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours))\n",
        "            \n",
        "            tf_slim.training.train(\n",
        "                train_op=train_op,\n",
        "                logdir=train_dir,\n",
        "                scaffold=scaffold,\n",
        "                hooks=hooks,\n",
        "                save_checkpoint_secs=60,\n",
        "                master=master,\n",
        "                is_chief=is_chief)\n",
        "\n",
        "# 학습 함수수\n",
        "def run(config_map,\n",
        "        tf_file_reader=tf.data.TFRecordDataset,\n",
        "        file_reader=tf.python_io.tf_record_iterator,\n",
        "        is_training=True):\n",
        "    config = config_map['cat-drums_4bar_small']\n",
        "    train_dir = './train_TFRecord'\n",
        "    num_steps = 50000 # 훈련 epoch\n",
        "    \n",
        "    def dataset_fn():\n",
        "        return data.get_dataset(\n",
        "            config,\n",
        "            tf_file_reader=tf_file_reader,\n",
        "            is_training=True,\n",
        "            cache_dataset=True)\n",
        "    \n",
        "    if is_training == True:\n",
        "        train(\n",
        "            train_dir,\n",
        "            config=config,\n",
        "            dataset_fn=dataset_fn,\n",
        "            num_steps=num_steps)      \n",
        "    \n",
        "    else:\n",
        "        print(\"EVAL\")"
      ],
      "metadata": {
        "id": "vvDfguKxbSt9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Train"
      ],
      "metadata": {
        "id": "jkC3iQAldycd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run(CONFIG_MAP) # epoch 50000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeeu7lZdd0dy",
        "outputId": "e31d87a4-e733-4df9-aee7-14c32ddb8572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://drive.google.com/file/d/1k1c8G6X-3dxltFHnc9oON_7JVEfbIs3t/view?usp=share_link  \n",
        "위 링크로 체크파일 zip 다운로드 가능"
      ],
      "metadata": {
        "id": "Z2Uvg-PF8Ks8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 생성"
      ],
      "metadata": {
        "id": "XbrI8oeTeAwr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "저장 될 디렉토리 생성"
      ],
      "metadata": {
        "id": "8_P70FBleJP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir(\"gen_midi\")"
      ],
      "metadata": {
        "id": "Iei57TGleB4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "magenta/magenta/models/music_vae/music_vae_generate.py 내용 일부 사용"
      ],
      "metadata": {
        "id": "BQCLaA4BfTHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=== magenta/magenta/models/music_vae/music_vae_generate.py ===\n",
        "model = TrainedModel(\n",
        "    config=CONFIG_MAP['cat-drums_4bar_small'],\n",
        "    batch_size=1,\n",
        "    checkpoint_dir_or_path='./train_TFRecord') # 체크포인트의 경로\n",
        "\n",
        "generated_sequence = model.sample(n=1, length=16*4, temperature=0.5)\n",
        "note_seq.sequence_proto_to_midi_file(generated_sequence[0], './gen_midi/cat-drums_4bar_small.mid')"
      ],
      "metadata": {
        "id": "IIGaoi_WebIc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}